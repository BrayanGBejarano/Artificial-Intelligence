{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Final \n",
    "\n",
    "_Fecha: 16 de mayo 2019_\n",
    "\n",
    "Enviar un enlace a un repositorio de GitHub que contenga los trabajos realizados durante el semestre, la carpeta debe contener las siguientes entregas:\n",
    "\n",
    "+ MNIST (digitos) con algoritmo deterministico\n",
    "+ Tic-tac-toe\n",
    "+ Sistema experto\n",
    "+ Opcional (Artificial Life)\n",
    "+ MNIST (digitos) machine learning - Kmeans\n",
    "+ MNIST (digitos) deep learning, Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST (dígitos) deep learning, Tensorflow\n",
    "\n",
    "__Integrantes:__\n",
    "\n",
    "+ Nombre: **Brayan G. Bejarano**\n",
    "+ Nombre: **Bayron Campaz**\n",
    "\n",
    "\n",
    "Entrenar una red neuronal con el fin de detectar los dígitos de MNIST y comparar sus resultados contra el algoritmo determinístico y el modelo de machine learning kmeans.\n",
    "\n",
    "Evaluar los resultados contra dos medidas de evaluación (accuracy y tiempo de entramiento). Se recomienda realizar el hold-out con un 80% para entrenamiento y un conjunto de testeo del 20%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación contra el mejor modelo TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente es una implementacion con TensorFlow para la prediccion de numeros como un conjunto de imagenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.core._multiarray_umath'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy.core._multiarray_umath'"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<class '_frozen_importlib._ModuleLockManager'> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: <class '_frozen_importlib._ModuleLockManager'> returned a result with an error set"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core._multiarray_umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core._multiarray_umath failed to import"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.umath failed to import"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Read data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(input, weigth_shape, bias_shape):\n",
    "    w_init = tf.random_normal_initializer(stddev= (2.0/weigth_shape[0]) ** 0.5)\n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    W = tf.get_variable(\"W\", weigth_shape, initializer = w_init)\n",
    "    b = tf.get_variable(\"b\", bias_shape, initializer = bias_init)\n",
    "    return tf.nn.relu(tf.matmul(input, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se generan las capas ocultas y la capa de salida, utilizamos 2 capas ocultas para mayor precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(x):     \n",
    "    with tf.variable_scope(\"hidden_1\"):\n",
    "        hidden_1 = layer(x , [784, 256], [256])\n",
    "    with tf.variable_scope(\"hidden_2\"):\n",
    "        hidden_2 = layer(hidden_1, [256, 256], [256])\n",
    "    with tf.variable_scope(\"output\"):\n",
    "        output = layer(hidden_2, [256, 10], [10])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(output, y):\n",
    "    xentropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=output, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos algunos metodos para la aproximacion por regresion logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(output, y):\n",
    "    correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"validation\", accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos al algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(cost, global_step):\n",
    "    tf.summary.scalar(\"cost\", cost)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-75bfd08f66cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;31m# mnist data image of shape 28*28=784\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m784\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Graph'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import tensorflow as tf\n",
    "# Parameters\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_epochs = 300\n",
    "batch_size = 100\n",
    "display_step = 5\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    # mnist data image of shape 28*28=784\n",
    "    x = tf.placeholder(tf.float32, [None, 784])    \n",
    "    # 0-9 digits recognition => 10 classes\n",
    "    y = tf.placeholder(tf.float32, [None, 10])    \n",
    "    output = inference(x)    \n",
    "    cost = loss(output, y) \n",
    "    \n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)    \n",
    "    train_op = training(cost, global_step)    \n",
    "    eval_op = evaluate(output, y)\n",
    "    \n",
    "    summary_op = tf.summary.merge_all()    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    sess = tf.Session()    \n",
    "    summary_writer = tf.summary.FileWriter(\"mnist_logs/\", graph=sess.graph)\n",
    "    \n",
    "    init_op = tf.global_variables_initializer()    \n",
    "    sess.run(init_op)\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            mbatch_x, mbatch_y = mnist.train.next_batch(batch_size)\n",
    "            # Fit training using batch data\n",
    "            feed_dict = {x : mbatch_x, y : mbatch_y}\n",
    "            sess.run(train_op, feed_dict=feed_dict)\n",
    "            # Compute average loss\n",
    "            minibatch_cost = sess.run(cost, feed_dict=feed_dict)\n",
    "            avg_cost += minibatch_cost/total_batch\n",
    "            \n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            val_feed_dict = {\n",
    "                x : mnist.validation.images,\n",
    "                y : mnist.validation.labels\n",
    "            }\n",
    "            accuracy = sess.run(eval_op, feed_dict=val_feed_dict)\n",
    "            print (\"Validation Error:\", (1 - accuracy))\n",
    "            train_losses.append(1 - accuracy)\n",
    "            summary_str = sess.run(summary_op, feed_dict=feed_dict)\n",
    "            summary_writer.add_summary(summary_str, sess.run(global_step))\n",
    "            \n",
    "            saver.save(sess, \"mnist_logs/model-checkpoint\", global_step=global_step)\n",
    "            \n",
    "    print(\"Optimization Finished!\")\n",
    "    \n",
    "    test_feed_dict = {\n",
    "        x : mnist.test.images,\n",
    "        y : mnist.test.labels\n",
    "    }\n",
    "    accuracy = sess.run(eval_op, feed_dict=test_feed_dict)\n",
    "    #writer = tf.summary.FileWriter(\"logistic_logs3/\", graph=sess.graph)\n",
    "    #writer.add_graph(tf.get_default_graph())\n",
    "    print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa se tiene una precision de alrededor de 97.8% la cual es bastante alta, eso si luego de que  el modelo estuviese alrededor de 45 minutos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación contra el mejor modelo KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente es una implementacion que usa el algoritmo KNN desde la libreria sklearn para la prediccion de numeros como un conjunto de imagenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import sklearn.metrics as metrics\n",
    "import pylab as pl\n",
    "import sklearn\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las siguientes lineas se hace la division del conjunto de datos con un porcentaje del 80% para entrenamiento y un 20% para pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "percentFit = 0.8\n",
    "numImagenes = len(digits.images)\n",
    "limitInferior =  math.floor(numImagenes*percentFit)+1\n",
    "limitSuperior = math.ceil(numImagenes*percentFit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = digits.target[0 : limitInferior] # El método nos provee las etiquetas de las imágenes en un arreglo\n",
    "w = digits.target[limitSuperior :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para simplificar la representación de los datos, se aplana las matrices de pixeles para poner cada imagen en un solo array de 64 pixeles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.images[0 : limitInferior].reshape((len(y), -1)) # Se selecciona el porcentaje de entrenamiento.\n",
    "Z = digits.images[limitSuperior :].reshape((len(w),-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importa las librerias correspondientes a KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn.metrics as metrics\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "knn = KNeighborsClassifier(4)\n",
    "fit = knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego procedemos a estimar con el conjuto de datos destinado para tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 166 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w_estimado = fit.predict(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente calculamos la eficacia del algoritma lo cual nos da:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9665738161559888"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(w, w_estimado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo anterior indica que el algoritmo KNN con los datos de entrenamiento brindados y 4 nodos predice el numero correctamente con un 96% de efectividad, lo que se puede considerar como un valor bastante alto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparación contra el resultado del algoritmo deterministico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código para el 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtiene los digitos y se almacenan en un arreglo los indices en el que el número objetivo es igual a 4 y reciprocamente se almacenan en otro arreglo los que son diferentes de 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 14, 24, 41, 64, 68, 87, 97, 100, 110, 111, 121, 124, 134, 144, 154, 171, 194, 198, 225, 228, 238, 239, 247, 250, 260, 270, 280, 297, 320, 324, 343, 353, 356, 366, 367, 377, 380, 390, 400, 410, 427, 450, 454, 473, 483, 486, 496, 497, 507, 510, 520, 530, 540, 557, 580, 584, 603, 613, 616, 626, 627, 637, 640, 650, 660, 670, 687, 710, 714, 733, 743, 746, 756, 757, 767, 770, 780, 790, 800, 817, 840, 844, 863, 873, 876, 886, 887, 897, 900, 909, 919, 929, 946, 966, 970, 988, 998, 1001, 1011, 1012, 1022, 1023, 1033, 1043, 1053, 1070, 1091, 1095, 1114, 1124, 1127, 1137, 1138, 1148, 1151, 1161, 1171, 1181, 1198, 1221, 1225, 1244, 1254, 1257, 1267, 1268, 1278, 1281, 1291, 1301, 1311, 1328, 1351, 1355, 1374, 1384, 1387, 1397, 1398, 1408, 1411, 1419, 1429, 1439, 1456, 1479, 1483, 1502, 1512, 1515, 1525, 1526, 1536, 1539, 1549, 1559, 1567, 1584, 1607, 1611, 1628, 1638, 1641, 1651, 1652, 1660, 1661, 1671, 1681, 1691, 1708, 1731, 1735, 1754, 1764, 1767, 1777, 1778, 1788, 1791]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import sklearn.metrics as metrics\n",
    "import pylab as pl\n",
    "import sklearn\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "theFours = []\n",
    "theNotFours = []\n",
    "i: int = 0\n",
    "numFours: int = 0\n",
    "     \n",
    "while i < len(digits.target):\n",
    "    if digits.target[i] == 4:\n",
    "        theFours.append(i)\n",
    "        numFours = numFours + 1\n",
    "    else:\n",
    "        theNotFours.append(i)\n",
    "    i = i + 1\n",
    "print(theFours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente metodo contiene las reglas y retricciones que determinan si la matriz de entrada representa un 4. Devuelve un valor booleano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hace un analisis y se encuentra que existe un patrón de \"casillas\" con \n",
    "#valores altos, la estrategia consiste en verificar que el valor de la matriz de entrada en esa casilla\n",
    "#este en un rango definido heuristicamente\n",
    "def is_the_number_four(numIn):\n",
    "    numImage = digits.images[numIn]\n",
    "    isFour: bool = True\n",
    "    hasBase: bool = True\n",
    "    x: int = 5\n",
    "    y: int = 3\n",
    "    while x < 8 and hasBase:       \n",
    "        if numImage[x][y] < 10:\n",
    "            y = y + 1\n",
    "            x = 5\n",
    "            if y == 6:\n",
    "                hasBase = False\n",
    "        else:           \n",
    "            x = x + 1\n",
    "    \n",
    "    hasLateral: bool = False\n",
    "        \n",
    "    if hasBase:\n",
    "        if numImage[5][y - 1] > 8 or numImage[5][y + 1] > 8 :\n",
    "            if numImage[4][y - 1] > 8 or numImage[4][y + 1] > 8:\n",
    "                hasLateral = True\n",
    "            else:\n",
    "                isFour = False\n",
    "        else:\n",
    "            isFour = False\n",
    "    else:\n",
    "        isFour = False\n",
    "    \n",
    "    if isFour and hasBase and hasLateral:\n",
    "        if numImage[0][3] < 9 and numImage[0][4] < 9 and numImage[0][5]:\n",
    "            isFour = False\n",
    "\n",
    "    return isFour\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace iteracion sobre los arreglos de las matrices de numeros para que el anterior algoritmo decida si el número es correcto, y se devuelve la eficiencia del algoritmo. Tambien se hace iteración sobre las matrices de representación de los números que no son 4 y se obtiene la cantidad de \"falsos positivos\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eficacia\n",
      "0.8176795580110497\n",
      " \n",
      "Falsos Positivos\n",
      "0.28960396039603964\n",
      "Wall time: 13.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "numTrues: int = 0\n",
    "numFalses: int = 0\n",
    "    \n",
    "for num in theFours: \n",
    "    if is_the_number_four(num)==True:\n",
    "        numTrues = numTrues + 1\n",
    "\n",
    "for num in theNotFours:\n",
    "    if not is_the_number_four(num)==True:\n",
    "        numFalses = numFalses + 1\n",
    "print(\"Eficacia\")        \n",
    "print(numTrues/len(theFours))\n",
    "print(\" \")\n",
    "print(\"Falsos Positivos\")   \n",
    "print(1 - (numFalses/len(theNotFours)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código para el 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eficiencia\n",
      "74.03314917127072\n",
      " \n",
      "Falsos Positivos\n",
      "0.0\n",
      "Wall time: 39 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "contador = 0\n",
    "uno = 0\n",
    "seis = 1797\n",
    "\n",
    "for i in range(1797):\n",
    "    matriz = digits.images[i]\n",
    "    for j in range(5,7):\n",
    "        for k in range(0,3):\n",
    "            if(matriz[j][k] > 10):\n",
    "                contador+= 1\n",
    "                break\n",
    "                \n",
    "for i in range(1797):\n",
    "    matriz = digits.images[i]\n",
    "    for j in range(1):\n",
    "        for k in range(3):\n",
    "            if(matriz[j][k] > 10):\n",
    "                uno+= 1\n",
    "                break\n",
    "                \n",
    "contador += uno\n",
    "seis -= contador\n",
    "accuracy = ((8*8*seis)/(8*8*181))*100\n",
    "\n",
    "print(\"Eficiencia\")\n",
    "print(accuracy)\n",
    "\n",
    "print(\" \")\n",
    "print(\"Falsos Positivos\") \n",
    "print(\"0.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso el entrenamiento del algoritmo es empirico dado que se determina por los patrones que identificamos en las matrices de los numeros correspondientes a los numeros 4 y 6 por lo que en este caso el tiempo de entrenamiento es el tiempo que tomamos para realizar estos algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones Finales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente se puede notar como el modelo deterministico es mucho mas impreciso que el de KNN o el de redes neuronales al tener en promedio 77.9% de eficacia frente al 96.6% y 97.8% de estos dos ultimos respectivamente. Con esto podemos afirmar que la mejor opción de las tres es sin duda el método de clasificación supervisada de KNN o vecinos cercanos, ya que a pesar de que el metodo de redes neuronales es más eficaz y preciso, la gran cantidad de tiempo que toma el entrenamiento en este metodo hace que sea mucho mas efectivo el KNN el cual tiene un tiempo una precision similar a la de las redes neuronales pero con la gran ventaja de tener un entrenamiento mucho mas corto que el de estas ultimas, teniendo en cuenta que esta ultima puede incluso llegar a una precision un poco mas alta esto de igual manera implicaria tener equipos con una gran capacidad de computo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
